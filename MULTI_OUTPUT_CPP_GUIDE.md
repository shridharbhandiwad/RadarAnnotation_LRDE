# Multi-Output Radar Tagging - C++ Implementation Guide

## Overview

This guide covers the C++ implementation for **multi-output** radar trajectory tagging models. Unlike single-class classification, multi-output models predict **11 binary tags simultaneously**:

### Output Tags

1. **Direction**: `incoming`, `outgoing`
2. **Vertical Motion**: `fixed_range_ascending`, `fixed_range_descending`, `level_flight`
3. **Path Shape**: `linear`, `curved`
4. **Maneuver Intensity**: `light_maneuver`, `high_maneuver`
5. **Speed**: `low_speed`, `high_speed`

### Supported Model Types

âœ… **Neural Networks** (LSTM, Transformer) - TensorFlow Lite  
âœ… **XGBoost** - JSON/ONNX export  
âœ… **Random Forest** - JSON/ONNX export  

## Quick Start

### 1. Convert Neural Network Model

```bash
cd /workspace
python3 convert_model_to_tflite.py --model-type lstm --output-dir cpp_models
```

### 2. Export XGBoost/Random Forest (if applicable)

```bash
# Export XGBoost models
python3 export_xgboost_models.py \
    --model output/xgboost_multioutput.pkl \
    --output-dir cpp_models_xgboost \
    --model-type xgboost \
    --format both

# Export Random Forest models
python3 export_xgboost_models.py \
    --model output/randomforest_multioutput.pkl \
    --output-dir cpp_models_rf \
    --model-type randomforest \
    --format onnx
```

### 3. Build C++ Application

```bash
cd cpp_inference
./build.sh  # or use CMake manually
```

This builds **two executables**:
- `radar_tagger` - Single-output (original)
- `radar_tagger_multioutput` - Multi-output (new)

### 4. Run Multi-Output Inference

```bash
cd build

# Neural Network (TFLite)
./radar_tagger_multioutput \
    --model ../cpp_models/lstm/lstm_model.tflite \
    --metadata ../cpp_models/lstm/model_metadata.json \
    --model-type nn

# With test data
./radar_tagger_multioutput \
    --model ../cpp_models/lstm/lstm_model.tflite \
    --metadata ../cpp_models/lstm/model_metadata.json \
    --model-type nn \
    --test-data ../cpp_models/lstm/test_data.bin \
    --test-binary
```

## Architecture

### Multi-Output Prediction Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Input: Radar Sequence         â”‚
â”‚   (20 timesteps Ã— 18 features)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Neural Network / XGBoost      â”‚
â”‚   (Multi-Output Model)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   11 Binary Predictions         â”‚
â”‚   â”œâ”€ incoming: 0.85 â†’ True      â”‚
â”‚   â”œâ”€ outgoing: 0.12 â†’ False     â”‚
â”‚   â”œâ”€ level_flight: 0.92 â†’ True  â”‚
â”‚   â”œâ”€ linear: 0.88 â†’ True        â”‚
â”‚   â”œâ”€ curved: 0.15 â†’ False       â”‚
â”‚   â”œâ”€ light_maneuver: 0.75 â†’ Trueâ”‚
â”‚   â”œâ”€ high_maneuver: 0.20 â†’ Falseâ”‚
â”‚   â”œâ”€ low_speed: 0.80 â†’ True     â”‚
â”‚   â”œâ”€ high_speed: 0.25 â†’ False   â”‚
â”‚   â””â”€ ...                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Aggregated Label              â”‚
â”‚   "incoming,level,linear,       â”‚
â”‚    light_maneuver,low_speed"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## C++ API Usage

### Basic Multi-Output Prediction

```cpp
#include "radar_tagger_multioutput.h"

int main() {
    // Create tagger with model type
    RadarTaggerMultiOutput tagger(
        "lstm_model.tflite",
        "metadata.json",
        ModelType::NEURAL_NETWORK,
        4  // threads
    );
    
    // Initialize
    if (!tagger.initialize()) {
        return 1;
    }
    
    // Prepare radar sequence
    RadarSequence sequence;
    // ... fill with radar data ...
    
    // Predict
    auto result = tagger.predict(sequence);
    
    if (result.success) {
        // Access multi-output tags
        std::cout << "Direction:\n";
        std::cout << "  Incoming: " << result.tags.incoming << "\n";
        std::cout << "  Outgoing: " << result.tags.outgoing << "\n";
        
        std::cout << "\nVertical Motion:\n";
        std::cout << "  Level Flight: " << result.tags.level_flight << "\n";
        std::cout << "  Ascending: " << result.tags.fixed_range_ascending << "\n";
        
        std::cout << "\nPath Shape:\n";
        std::cout << "  Linear: " << result.tags.linear << "\n";
        std::cout << "  Curved: " << result.tags.curved << "\n";
        
        // Get aggregated label
        std::cout << "\nAggregated: " << result.aggregatedLabel << "\n";
        
        // Access confidences
        for (const auto& [tag, conf] : result.tags.confidences) {
            std::cout << "  " << tag << ": " << conf << "\n";
        }
    }
    
    return 0;
}
```

### Evaluation with Ground Truth

```cpp
// Load data with ground truth
auto [sequences, groundTruths] = 
    RadarTaggerMultiOutput::loadFromCSV("data.csv", true);

// Predict and evaluate
for (size_t i = 0; i < sequences.size(); i++) {
    auto result = tagger.predict(sequences[i], &groundTruths[i]);
    
    if (result.success) {
        // Check per-tag accuracy
        for (const auto& [tag, correct] : result.correctPredictions) {
            std::cout << tag << ": " << (correct ? "âœ“" : "âœ—") << "\n";
        }
        
        std::cout << "Overall Accuracy: " 
                  << result.overallAccuracy << "\n";
    }
}

// Get aggregate metrics
auto metrics = tagger.getMetrics();
metrics.print();  // Shows per-tag accuracy, F1 scores, etc.
```

### Batch Processing

```cpp
std::vector<RadarSequence> sequences = loadDataFromFile("batch.csv");

// Process all sequences
auto results = tagger.predictBatch(sequences);

// Analyze results
for (const auto& result : results) {
    auto activeTags = result.tags.getActiveTags();
    std::cout << "Tags: ";
    for (const auto& tag : activeTags) {
        std::cout << tag << " ";
    }
    std::cout << "\n";
}
```

## Model-Specific Guides

### Neural Networks (TFLite)

**Status**: âœ… Fully Implemented

**Best for**: 
- Sequential models (LSTM, Transformer)
- Real-time inference
- Edge deployment

**Conversion**:
```bash
python3 convert_model_to_tflite.py --model-type lstm --output-dir cpp_models
```

**C++ Usage**:
```bash
./radar_tagger_multioutput \
    --model lstm_model.tflite \
    --metadata metadata.json \
    --model-type nn
```

**Performance**:
- Inference Time: 2-5 ms
- Throughput: 200-400 predictions/sec
- Memory: < 1 MB

### XGBoost

**Status**: âš ï¸ Export Only (C++ inference requires XGBoost C++ API)

**Best for**:
- Tabular features
- Fast training
- High accuracy

**Export**:
```bash
python3 export_xgboost_models.py \
    --model xgboost_model.pkl \
    --output-dir cpp_models_xgb \
    --format both
```

**Output**:
- JSON format (per tag)
- Binary format (.bin)
- ONNX format (recommended for C++)

**C++ Integration Options**:

1. **ONNX Runtime** (Recommended):
```cpp
// Use ONNX Runtime C++ API
#include <onnxruntime/core/session/onnxruntime_cxx_api.h>

Ort::Env env;
Ort::Session session(env, "xgboost_model.onnx", options);
// ... inference ...
```

2. **XGBoost C++ API**:
```cpp
#include <xgboost/c_api.h>

BoosterHandle booster;
XGBoosterCreate(NULL, 0, &booster);
XGBoosterLoadModel(booster, "model.json");
// ... inference ...
```

### Random Forest

**Status**: âš ï¸ Export Only (C++ inference requires sklearn-porter or ONNX)

**Best for**:
- Robustness
- Interpretability
- Ensemble methods

**Export**:
```bash
python3 export_xgboost_models.py \
    --model rf_model.pkl \
    --output-dir cpp_models_rf \
    --format onnx
```

**C++ Integration**:
Use ONNX Runtime (same as XGBoost above)

## Data Formats

### CSV Format with Ground Truth

```csv
time,trackid,x,y,z,vx,vy,vz,ax,ay,az,speed,speed_2d,heading,range,range_rate,curvature,accel_magnitude,vertical_rate,altitude_change,incoming,outgoing,fixed_range_ascending,fixed_range_descending,level_flight,linear,curved,light_maneuver,high_maneuver,low_speed,high_speed,Annotation
0.0,1.0,10000,10000,2000,-26.68,22.66,0,0,0,0,35.0,35.0,310.34,14282.86,0,0,0,0,0,1,0,0,0,1,1,0,1,0,1,0,"incoming,level,linear,light_maneuver,low_speed"
```

**Columns**:
- Columns 0-19: Radar features
- Columns 20-30: Ground truth tags (0/1)
- Column 31: Aggregated annotation

### Binary Format

```
[n_samples][sequence_length][n_features]
- Data type: float32
- Contiguous memory layout
- No ground truth included
```

## Performance Metrics

### Per-Tag Metrics

The C++ application computes detailed metrics for each tag:

```
=== Per-Tag Accuracy ===
  incoming                  : 92.5%
  outgoing                  : 94.1%
  fixed_range_ascending     : 88.3%
  fixed_range_descending    : 89.7%
  level_flight              : 95.2%
  linear                    : 93.8%
  curved                    : 91.4%
  light_maneuver            : 90.6%
  high_maneuver             : 89.2%
  low_speed                 : 92.8%
  high_speed                : 93.5%

Overall Accuracy: 92.1%
Average F1 Score: 0.918
```

### Confusion Matrix (Per Tag)

For each tag, the system tracks:
- **True Positives**: Correctly predicted active tags
- **False Positives**: Incorrectly predicted active tags
- **True Negatives**: Correctly predicted inactive tags
- **False Negatives**: Missed active tags

## Command Line Reference

### Neural Network Model

```bash
# Basic inference
./radar_tagger_multioutput \
    --model model.tflite \
    --metadata metadata.json \
    --model-type nn

# With CSV data
./radar_tagger_multioutput \
    --model model.tflite \
    --metadata metadata.json \
    --model-type nn \
    --test-data data.csv

# With evaluation
./radar_tagger_multioutput \
    --model model.tflite \
    --metadata metadata.json \
    --model-type nn \
    --test-data data.csv \
    --load-gt

# With binary data
./radar_tagger_multioutput \
    --model model.tflite \
    --metadata metadata.json \
    --model-type nn \
    --test-data test.bin \
    --test-binary \
    --samples 10 \
    --seq-length 20 \
    --features 18

# Benchmark mode
./radar_tagger_multioutput \
    --model model.tflite \
    --metadata metadata.json \
    --model-type nn \
    --test-data test.bin \
    --test-binary \
    --benchmark

# Adjust threading
./radar_tagger_multioutput \
    --model model.tflite \
    --metadata metadata.json \
    --model-type nn \
    --threads 8
```

### XGBoost Model (Future)

```bash
# Note: Requires XGBoost C++ library or ONNX Runtime
./radar_tagger_multioutput \
    --model xgboost_model.json \
    --metadata metadata.json \
    --model-type xgboost
```

## Integration Examples

### Real-Time Processing

```cpp
RadarTaggerMultiOutput tagger("model.tflite", "metadata.json", 
                              ModelType::NEURAL_NETWORK);
tagger.initialize();

// Process incoming radar data stream
while (radar_active) {
    RadarDataPoint newPoint = getNextRadarPoint();
    currentSequence.points.push_back(newPoint);
    
    if (currentSequence.points.size() >= 20) {
        auto result = tagger.predict(currentSequence);
        
        if (result.success) {
            // Act on tags
            if (result.tags.incoming && result.tags.high_speed) {
                alertHighSpeedApproach();
            }
            
            if (result.tags.high_maneuver) {
                trackEvasiveTarget();
            }
        }
        
        // Sliding window
        currentSequence.points.erase(currentSequence.points.begin());
    }
}
```

### Tag-Specific Processing

```cpp
auto result = tagger.predict(sequence);

if (result.success) {
    // Direction-based processing
    if (result.tags.incoming) {
        handleIncomingTarget(sequence.trackId);
    } else if (result.tags.outgoing) {
        handleOutgoingTarget(sequence.trackId);
    }
    
    // Maneuver-based alerts
    if (result.tags.high_maneuver && 
        result.tags.confidences["high_maneuver"] > 0.9) {
        raiseHighManeuverAlert(sequence.trackId);
    }
    
    // Speed-based filtering
    if (result.tags.high_speed) {
        prioritizeTrack(sequence.trackId);
    }
}
```

## Troubleshooting

### Build Issues

**Problem**: Undefined reference to TFLite functions  
**Solution**: Ensure TensorFlow Lite is properly linked in CMakeLists.txt

**Problem**: Multiple definition errors  
**Solution**: Use `#pragma once` or include guards in headers

### Runtime Issues

**Problem**: Output size mismatch  
**Solution**: Verify model outputs 11 values (one per tag)

**Problem**: All tags False  
**Solution**: Check threshold (default 0.5), verify model calibration

### Performance Issues

**Problem**: Slow inference on multi-output  
**Solution**: Use batch processing, increase threads

**Problem**: High memory usage  
**Solution**: Process sequences in batches, clear old data

## Comparison: Single vs. Multi-Output

| Aspect | Single-Output | Multi-Output |
|--------|---------------|--------------|
| **Output** | 1 class (20 possible) | 11 binary tags |
| **Granularity** | Coarse | Fine-grained |
| **Flexibility** | Fixed combinations | Any tag combination |
| **Training** | One model | Multiple models or multi-head |
| **Inference** | Slightly faster | Slightly slower |
| **Interpretability** | Limited | High (see individual tags) |

## Best Practices

### Model Selection

1. **Neural Networks**: Use for sequential data, real-time needs
2. **XGBoost**: Use for tabular features, high accuracy
3. **Random Forest**: Use for robustness, interpretability

### Deployment

1. **Edge Devices**: Use TFLite (small, optimized)
2. **Servers**: Use ONNX Runtime (flexible, performant)
3. **Embedded**: Use quantized TFLite models

### Performance

1. **Latency-Critical**: Use TFLite with threading
2. **Throughput-Critical**: Use batch processing
3. **Memory-Limited**: Use quantized models

## Next Steps

1. **Test**: Run evaluation on your data
2. **Optimize**: Tune thresholds for your use case
3. **Deploy**: Integrate into your application
4. **Monitor**: Track per-tag performance in production

## Resources

- TensorFlow Lite C++ Guide: https://www.tensorflow.org/lite/guide/inference
- ONNX Runtime C++ API: https://onnxruntime.ai/docs/api/c/
- XGBoost C++ API: https://xgboost.readthedocs.io/en/latest/
- Parent Project: `README.md`

---

**Multi-Output C++ implementation complete and ready for deployment!** ğŸš€
