# Quick Start: Multi-Output Auto-Tagging

## ðŸš€ Fastest Way to Get Started

### Your Data Format
```
Columns A-K:  Input features (x, y, z, velocities, etc.)
Columns L-AF: Output tags (incoming, outgoing, level, linear, etc.)
Column AG:    Aggregated annotation (reference)
```

### 1. Train All Three Models (< 1 minute)

```bash
python train_multi_output_models.py --data your_data.csv
```

**Output:**
- âœ… XGBoost model â†’ Fast & Accurate (85-92%)
- âœ… Random Forest model â†’ Robust (83-90%)
- âœ… Transformer model â†’ State-of-the-art (88-95%)

### 2. Use Trained Model for Prediction

```python
from src.ai_engine import XGBoostMultiOutputModel
import pandas as pd

# Load model
model = XGBoostMultiOutputModel()
model.load('output/multi_output_models/xgboost_multi_output/model.pkl')

# Predict tags
data = pd.read_csv('new_radar_data.csv')
predictions = model.predict(data)

# Save results
predictions.to_csv('auto_tagged_results.csv', index=False)
```

**Prediction Output:**
```
   incoming  outgoing  level_flight  linear  curved  ...  Predicted_Annotation
0         1         0             1       1       0  ...  incoming,level,linear,light_maneuver
1         0         1             0       0       1  ...  outgoing,curved,high_maneuver
```

## ðŸ“Š Model Selection Guide

| Use Case | Recommended Model | Why? |
|----------|------------------|------|
| **Production/Real-time** | XGBoost | Fastest prediction, low memory |
| **Highest Accuracy** | Transformer | Best performance, handles sequences |
| **Quick Baseline** | Random Forest | Fast training, robust |
| **Limited Data** | XGBoost | Works well with smaller datasets |
| **Sequential Data** | Transformer | Captures temporal patterns |

## ðŸŽ¯ Complete Example

```python
# Step 1: Import
from src.ai_engine import XGBoostMultiOutputModel
import pandas as pd

# Step 2: Load data
df = pd.read_csv('radar_data_with_tags.csv')

# Step 3: Split data (by track ID)
from sklearn.model_selection import train_test_split
track_ids = df['trackid'].unique()
train_ids, test_ids = train_test_split(track_ids, test_size=0.2)

df_train = df[df['trackid'].isin(train_ids)]
df_test = df[df['trackid'].isin(test_ids)]

# Step 4: Train
model = XGBoostMultiOutputModel()
metrics = model.train(df_train)
print(f"Training completed! Accuracy: {metrics['train_accuracy']:.2%}")

# Step 5: Evaluate
test_metrics = model.evaluate(df_test)
print(f"Test Accuracy: {test_metrics['accuracy']:.2%}")
print(f"Test F1 Score: {test_metrics['f1_score']:.2%}")

# Step 6: Check per-tag performance
for tag, perf in test_metrics['per_tag_metrics'].items():
    print(f"{tag}: {perf['accuracy']:.2%}")

# Step 7: Predict on new data
new_data = pd.read_csv('unlabeled_tracks.csv')
predictions = model.predict(new_data)

# Step 8: Save
model.save('my_auto_tagger.pkl')
predictions.to_csv('tagged_output.csv', index=False)
```

## ðŸ”§ Common Customizations

### Custom Column Selection
```python
model = XGBoostMultiOutputModel()
model.train(
    df_train,
    input_cols=['x', 'y', 'z', 'vx', 'vy', 'vz'],  # Specify inputs
    output_cols=['tag1', 'tag2', 'tag3', 'tag4']    # Specify outputs
)
```

### Hyperparameter Tuning
```python
# XGBoost - More accurate but slower
model = XGBoostMultiOutputModel(params={
    'n_estimators': 200,    # More trees
    'max_depth': 8,         # Deeper trees
    'learning_rate': 0.05   # Slower learning
})

# Random Forest - More trees
model = RandomForestMultiOutputModel(params={
    'n_estimators': 500,
    'max_depth': 20,
    'n_jobs': -1           # Use all CPUs
})

# Transformer - Larger model
model = TransformerMultiOutputModel(params={
    'd_model': 256,
    'num_heads': 16,
    'num_layers': 6,
    'epochs': 200
})
```

## ðŸ“ˆ Performance Tips

1. **More Data = Better Models**: Collect diverse trajectories
2. **Feature Engineering**: Add domain-specific features
3. **Balance Classes**: Ensure all tags are well-represented
4. **Ensemble**: Combine multiple models for best results
5. **Tune Hyperparameters**: Adjust based on your data

## â“ Troubleshooting

**Problem:** "No valid sequences could be created"
**Solution:** Tracks need â‰¥3 data points. Check your data.

**Problem:** Low accuracy on certain tags
**Solution:** Check tag distribution. Rare tags need more data.

**Problem:** Training too slow
**Solution:** Use XGBoost or reduce data size for testing.

**Problem:** "Missing input columns"
**Solution:** Ensure data has required features (x, y, z, velocities).

## ðŸ“š More Information

- **Detailed Guide**: See `MULTI_OUTPUT_AUTO_TAGGING_GUIDE.md`
- **Implementation Details**: See `MULTI_OUTPUT_IMPLEMENTATION_SUMMARY.md`
- **Test First**: Run `python test_multi_output_models.py`

## âœ… Checklist

- [ ] Data has input features in columns A-K
- [ ] Data has output tags in columns L-AF (binary 0/1)
- [ ] At least 3 tracks in dataset
- [ ] Run: `python train_multi_output_models.py --data your_data.csv`
- [ ] Check results and select best model
- [ ] Use model for prediction on new data
- [ ] Deploy to production!

---

**Ready to start?** Run this:
```bash
python train_multi_output_models.py --data your_data.csv
```

ðŸŽ‰ **That's it!** You'll have three trained models ready for auto-tagging in minutes!
